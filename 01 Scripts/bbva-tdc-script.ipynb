{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "477d2431",
   "metadata": {},
   "source": [
    "### Provision Layer for BBVA bank, credit account\n",
    "\n",
    "**Author**: Ricardo Pérez Castillo\n",
    "\n",
    "**Latest update**: 2024-12-30\n",
    "\n",
    "**Version**: 6.0\n",
    "\n",
    "**Purpose**: Prepare expense data into an unified single source of truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211c39c",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Raw File Importing](#raw-file-importing)\n",
    "3. [Data Description](#data-description)\n",
    "4. [Basic Data Cleansing](#basic-data-cleansing)\n",
    "5. [Entity Harmonization](#entity-harmonization)\n",
    "6. [Transaction Type Definition](#transaction-type-definition)\n",
    "7. [Data Cleansing and Transformation](#data-cleansing-and-transformation)\n",
    "8. [Exporting](#exporting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad29c7",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "BBVA is one of the largest banks in México, offering debit and credit accounts. Data extraction is a challenge, since the bank does not offer API usage. Instead, manual extraction is needed. I use the custom dates option to filter the entire month in one file, however for debit accounts, it is only possible to extract from the latest 2 months, this is quite unfortunate as if you forget to extract the data for one month, then there is no other way to get the data, besides the bank statement which is in PDF format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2e22e",
   "metadata": {},
   "source": [
    "### Raw File Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15711487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical computations\n",
    "from datetime import datetime  # To handle date and time operations\n",
    "import pathlib  # For handling and manipulating file paths in an object-oriented way\n",
    "\n",
    "# Import custom configurations and mappings\n",
    "from config import current_month, current_month_text, current_year  # Custom configurations for date handling\n",
    "from entity_mapping import entity_mapping  # Predefined mapping for harmonizing entities\n",
    "from transaction_subtype_mapping import transaction_subtype_mapping  # Predefined mapping for harmonizing transaction subtypes\n",
    "\n",
    "# Import utilities for fuzzy matching\n",
    "from difflib import get_close_matches  # To find close matches between strings\n",
    "\n",
    "# Import utilities for generating hash values\n",
    "import hashlib  # For generating hash values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f01ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory for file storage\n",
    "base_dir = pathlib.Path.home() / \"Documents\" / \"Finanzas\"\n",
    "# The pathlib.Path.home() dynamically retrieves the user's home directory.\n",
    "\n",
    "# Define the input directory for files\n",
    "input_dir = base_dir / \"BBVA\" / \"BBVA TDC\" / \"Movimientos\" / \"2024\"\n",
    "# This constructs the full path to the directory where input files are stored.\n",
    "# Example: \"C:/Users/YourUserName/Documents/Finanzas/BBVA/BBVA TDC/Movimientos/2024\"\n",
    "\n",
    "# Define the output directory for processed files\n",
    "output_dir = base_dir / \"Personal Spend\" / \"02 Individual Datasets\" / \"2024\"\n",
    "# This constructs the full path to the directory where processed output files will be saved.\n",
    "# Example: \"C:/Users/YourUserName/Documents/Finanzas/Personal Spend/02 Individual Datasets/2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32244117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct the input file path for a specific month and year\n",
    "def get_filename_input(month, year, month_text, prefix=\"\", suffix=\"\", extension=\".xlsx\"):\n",
    "    \"\"\"\n",
    "    Constructs a filename for the input file based on the provided parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - month (int): The numeric month (e.g., 1 for January, 12 for December).\n",
    "    - year (int): The year (e.g., 2024).\n",
    "    - month_text (str): The textual representation of the month (e.g., \"January\").\n",
    "    - prefix (str): An optional prefix for the file name (default is an empty string).\n",
    "    - suffix (str): An optional suffix for the file name (default is an empty string).\n",
    "    - extension (str): The file extension (default is \".xlsx\").\n",
    "\n",
    "    Returns:\n",
    "    - str: The constructed file name (e.g., \"01_suffix.xlsx\").\n",
    "    \"\"\"\n",
    "    return str(month).zfill(2) + suffix + extension\n",
    "\n",
    "\n",
    "# Function to construct the output file path for a specific month and year\n",
    "def get_filename_output(month, year, month_text, prefix=\"\", suffix=\"\", extension=\".csv\"):\n",
    "    \"\"\"\n",
    "    Constructs a filename for the output file based on the provided parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - month (int): The numeric month (e.g., 1 for January, 12 for December).\n",
    "    - year (int): The year (e.g., 2024).\n",
    "    - month_text (str): The textual representation of the month (e.g., \"January\").\n",
    "    - prefix (str): An optional prefix for the file name (default is an empty string).\n",
    "    - suffix (str): An optional suffix for the file name (default is an empty string).\n",
    "    - extension (str): The file extension (default is \".csv\").\n",
    "\n",
    "    Returns:\n",
    "    - str: The constructed file name with the format \"month_text/month_textMM.csv\".\n",
    "    \"\"\"\n",
    "    return f\"{month_text}/{prefix}{month_text}{str(month).zfill(2)}{extension}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file paths for the current month's input and output files\n",
    "\n",
    "# Construct the full input file path\n",
    "input_file = input_dir / get_filename_input(\n",
    "    current_month,\n",
    "    current_year,\n",
    "    current_month_text,\n",
    "    prefix=\"\",\n",
    "    suffix=\"-descarga\"\n",
    ")\n",
    "\n",
    "# Construct the full output file path\n",
    "output_file = output_dir / get_filename_output(\n",
    "    current_month,\n",
    "    current_year,\n",
    "    current_month_text,\n",
    "    prefix=\"df-bbva-tdc-\",\n",
    "    suffix=\"\"\n",
    ")\n",
    "\n",
    "# Print the constructed file paths\n",
    "print(\"Input file path: \", input_file)\n",
    "print(\"Output file path: \", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be60a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import monthly data from the specified Excel file\n",
    "\n",
    "try:\n",
    "    # Attempt to read the Excel file, skipping the first 2 rows\n",
    "    df_bbva = pd.read_excel(input_file, skiprows=2)\n",
    "    print(\"Data imported successfully!\")\n",
    "except FileNotFoundError:\n",
    "    # Handle the case where the input file is not found\n",
    "    print(f\"File not found: {input_file}\")\n",
    "except Exception as e:\n",
    "    # Handle any other exceptions that may occur during file import\n",
    "    print(f\"An error occurred while reading the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3389b3",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "Extract contains\n",
    "- **FECHA**: Date in DD/MM/YYYY format\n",
    "- **DESCRIPCIÓN**: Description that contains the entity.\n",
    "- **CARGO**: Charged amount, mxn\n",
    "- **ABONO**: Credit (refunds, voids, etc) or Credit Card payments, mxn\n",
    "- **SALDO**: Balance, mxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6356bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first few rows of the imported data\n",
    "try:\n",
    "    # Display the first five rows of the DataFrame\n",
    "    print(\"Preview of the imported data:\")\n",
    "    display(df_bbva.head())\n",
    "except NameError:\n",
    "    # Handle the case where the DataFrame does not exist\n",
    "    print(\"The data has not been successfully loaded into a DataFrame. Please check the file import process.\")\n",
    "except Exception as e:\n",
    "    # Handle any other unexpected errors\n",
    "    print(f\"An error occurred during data visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92891d28",
   "metadata": {},
   "source": [
    "### Basic Data Cleansing\n",
    "\n",
    "This section focuses on preparing the financial dataset for analysis by removing irrelevant rows, handling missing values, transforming data types, and splitting columns for better structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f026653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevant rows based on the 'FECHA' column\n",
    "df_bbva = df_bbva[df_bbva['FECHA'] != 'BBVA México, S.A., Institución de Banca Múltiple, Grupo Financiero BBVA México.']\n",
    "df_bbva = df_bbva[df_bbva['FECHA'] != '     Digital ****']\n",
    "df_bbva = df_bbva[df_bbva['FECHA'] != '     Titular ****']\n",
    "\n",
    "# Drop rows where the 'FECHA' column has missing values\n",
    "df_bbva = df_bbva.dropna(subset=['FECHA'])\n",
    "\n",
    "# Remove duplicated payment system entries for installment payments\n",
    "# Example: \"01 DE 03\" indicates part of a payment installment plan\n",
    "df_bbva = df_bbva[df_bbva['DESCRIPCIÓN'].str.contains(\"01 DE 03\") == False]\n",
    "\n",
    "# Remove credit card payment rows as they will already appear in another dataset (BBVA TDB)\n",
    "df_bbva = df_bbva[df_bbva['DESCRIPCIÓN'].str.contains(\"PAGO TDC\") == False]\n",
    "\n",
    "# Transform the 'FECHA' column to datetime format\n",
    "df_bbva['FECHA'] = pd.to_datetime(df_bbva['FECHA'], format=\"%d/%m/%Y\")\n",
    "# Converts the 'FECHA' column to a standardized datetime format (\"%d/%m/%Y\").\n",
    "# This ensures the dates are consistent and can be used for time-based analysis.\n",
    "\n",
    "# Convert numeric columns to float\n",
    "df_bbva['CARGO'] = df_bbva['CARGO'].astype(float)\n",
    "df_bbva['ABONO'] = df_bbva['ABONO'].astype(float)\n",
    "# Ensures that the 'CARGO' and 'ABONO' columns are stored as floats for numerical operations.\n",
    "\n",
    "# Replace null values with zero\n",
    "df_bbva['CARGO'] = df_bbva['CARGO'].fillna(0)\n",
    "df_bbva['ABONO'] = df_bbva['ABONO'].fillna(0)\n",
    "# Fills any missing values in the 'CARGO' and 'ABONO' columns with zero.\n",
    "# This ensures calculations involving these columns are not affected by null values.\n",
    "\n",
    "# Convert expenses ('CARGO') to negative values\n",
    "df_bbva['CARGO'] = df_bbva['CARGO'] * -1\n",
    "# Multiplies all values in the 'CARGO' column by -1 to indicate these are expenses (negative values).\n",
    "# This makes it clear that these transactions are outflows of money.\n",
    "\n",
    "# Convert deposits ('ABONO') to positive values\n",
    "df_bbva['ABONO'] = df_bbva['ABONO'] * -1\n",
    "# Multiplies all values in the 'ABONO' column by -1 to ensure deposits are positive values.\n",
    "# This standardizes inflows of money as positive amounts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacee5d",
   "metadata": {},
   "source": [
    "### Entity Harmonization\n",
    "\n",
    "This section focuses on standardizing supplier names within the dataset by applying fuzzy matching techniques against a predefined mapping. The goal is to ensure consistency in supplier names for easier analysis and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "049a38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_supplier(supplier_name, entity_mapping):\n",
    "    \"\"\"\n",
    "    Harmonizes a supplier name using fuzzy matching against a predefined mapping.\n",
    "\n",
    "    Parameters:\n",
    "    - supplier_name (str): The name of the supplier to be harmonized.\n",
    "    - entity_mapping (dict): A dictionary where keys are potential supplier names \n",
    "                             and values are their harmonized names.\n",
    "\n",
    "    Returns:\n",
    "    - str: The harmonized supplier name if a close match is found; \n",
    "           otherwise, returns the original supplier name.\n",
    "    \"\"\"\n",
    "    # Use fuzzy matching to find potential matches for the supplier name\n",
    "    matches = get_close_matches(supplier_name, entity_mapping.keys(), n=1, cutoff=0.8)\n",
    "    \n",
    "    # Return the harmonized name if a close match is found\n",
    "    if matches:\n",
    "        return entity_mapping[matches[0]]\n",
    "    \n",
    "    # Return the original name if no close match is found\n",
    "    return supplier_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f353bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of suppliers from the 'DESCRIPCION_ENTIDAD' column\n",
    "suppliers_to_harmonize = df_bbva['DESCRIPCIÓN'].tolist()\n",
    "\n",
    "# Step 1: Harmonize the supplier names using the mapping\n",
    "harmonized_suppliers = [harmonize_supplier(supplier, entity_mapping) for supplier in suppliers_to_harmonize]\n",
    "\n",
    "# Step 2: Add the harmonized supplier names back to the DataFrame as a new column\n",
    "df_bbva['Harmonized_Supplier'] = harmonized_suppliers\n",
    "\n",
    "\n",
    "# Step 3: Display both 'DESCRIPCION_ENTIDAD' and 'Harmonized_Supplier' for comparison\n",
    "print(\"Comparison of original and harmonized supplier names:\")\n",
    "display(df_bbva[['DESCRIPCIÓN', 'Harmonized_Supplier']])\n",
    "\n",
    "# Step 4: Review the output and if necessary, update the entity_mapping.py dictionary and re-run the script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc0a70",
   "metadata": {},
   "source": [
    "### Transaction Type Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "781b5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign transaction type descriptions based on the 'ABONO' column\n",
    "df_bbva['TXT_TRANSACTION_TYPE'] = np.where(\n",
    "    df_bbva['ABONO'] != 0,  # Condition: If the value in 'ABONO' is not zero\n",
    "    \"Deposit\",             # Value to assign if the condition is True\n",
    "    \"Expense\"                 # Value to assign if the condition is False\n",
    ")\n",
    "# Transactions with non-zero values in the 'ABONO' column are categorized as \"Deposit\".\n",
    "# All other transactions are categorized as \"Cargo\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43c95f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately the data doesn't have enough information to define the transaction subtype, so it will be almost the same as the transaction type\n",
    "\n",
    "# Assign transaction type descriptions based on the 'ABONO' column\n",
    "df_bbva['TXT_TRANSACTION_SUBTYPE'] = np.where(\n",
    "    df_bbva['ABONO'] != 0,  # Condition: If the value in 'ABONO' is not zero\n",
    "    \"Refund\",             # Value to assign if the condition is True\n",
    "    \"Expense\"                 # Value to assign if the condition is False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fe4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbva.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149d2c3",
   "metadata": {},
   "source": [
    "### Data Cleansing and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d87b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that identifies the source system\n",
    "df_bbva['KEY_SYSTEM'] = 'BBVA'\n",
    "\n",
    "# Create a new column that identifies the source account\n",
    "df_bbva['KEY_ACCOUNT'] = 'BBVATDC'\n",
    "df_bbva['TXT_ACCOUNT'] = 'BBVA TDC'\n",
    "\n",
    "# Create a new column that combines CARGO and ABONO columns\n",
    "df_bbva['NUM_AMT_NET_REPORTING'] = np.where(df_bbva['CARGO'] != 0, df_bbva['CARGO'], df_bbva['ABONO']).astype(float)\n",
    "\n",
    "# Create columns that contains the currency-related information\n",
    "df_bbva['NUM_AMT_DOCUMENT'] = df_bbva['NUM_AMT_NET_REPORTING']\n",
    "df_bbva['KEY_CURRENCY_DOCUMENT'] = 'MXN'\n",
    "df_bbva['KEY_RATE'] = 1.0\n",
    "\n",
    "# Create new columns with time information\n",
    "df_bbva['KEY_MONTH'] = df_bbva['FECHA'].dt.month\n",
    "df_bbva['KEY_YEAR'] = df_bbva['FECHA'].dt.year\n",
    "\n",
    "# Create a new column that contains the flag indicating whether the transaction is debit or credit\n",
    "df_bbva['FLG_DEBIT_CREDIT'] = np.where(df_bbva['CARGO'] != 0, 'C', 'D')\n",
    "\n",
    "# Create new columns that identify the grouping operation (project, vacation, etc.). These will be blank and filled in later.\n",
    "df_bbva['KEY_OPERATION'] = ''\n",
    "df_bbva['TXT_OPERATION'] = ''\n",
    "\n",
    "# Create new columns relevant for credit card transactions and payments in installments. Not relevant for this account.\n",
    "df_bbva['DUE_DATE'] = ''\n",
    "df_bbva['KEY_PAYMENT_TERM'] = ''\n",
    "df_bbva['TXT_PAYMENT_TERM'] = ''\n",
    "df_bbva['NUM_AMT_DUE'] = ''\n",
    "df_bbva['KEY_ID_DUE'] = ''\n",
    "df_bbva['TXT_ENTITY_DUE'] = ''\n",
    "df_bbva['TXT_DESC_DUE'] = ''\n",
    "\n",
    "# Create new columns with the country information. This account does not provide the country information.\n",
    "df_bbva['KEY_COUNTRY'] = 'MX'\n",
    "df_bbva['TXT_COUNTRY'] = 'Mexico'\n",
    "\n",
    "# Create a new column with the purchase document number, blank initially.\n",
    "df_bbva['KEY_PURCH_DOC_NO'] = ''\n",
    "\n",
    "# Create a new column with internal flag\n",
    "df_bbva['FLG_INTERNAL'] = np.where(df_bbva['Harmonized_Supplier'] == 'BBVA Your Name', 'Y', 'N')\n",
    "\n",
    "# Create a new column with flag indicating whether the transaction was canceled\n",
    "df_bbva['FLG_CANCEL'] = ''\n",
    "\n",
    "# Create a new column with flag indicating whether the transaction was refunded\n",
    "df_bbva['FLG_REFUND'] = (\n",
    "    (df_bbva['ABONO'] > 0) & \n",
    "    (~df_bbva['DESCRIPCIÓN'].isin([\"BMOVIL.PAGO TDC\"]))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Create new columns that will be filled later with the master tables\n",
    "df_bbva['KEY_ENTITY'] = ''\n",
    "df_bbva['KEY_TRANSACTION_TYPE'] = ''\n",
    "df_bbva['KEY_TRANSACTION_SUBTYPE'] = ''\n",
    "\n",
    "# Rename the columns to match the standard naming convention\n",
    "df_bbva.rename(columns={\n",
    "    'FECHA': 'KEY_DATE',\n",
    "    'DESCRIPCIÓN': 'TXT_DESC',\n",
    "    'Harmonized_Supplier': 'TXT_ENTITY'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbfafe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a hash\n",
    "def generate_shorter_hash(row):\n",
    "    concat_str = f\"{row['KEY_DATE']}_{row['TXT_ENTITY']}_{row['TXT_TRANSACTION_SUBTYPE']}_{row['NUM_AMT_NET_REPORTING']}\"\n",
    "    return hashlib.md5(concat_str.encode('utf-8')).hexdigest()  # MD5 generates a 32-character hash\n",
    "\n",
    "# Apply the function to create the hash-based KEY_ID\n",
    "df_bbva['KEY_ID'] = df_bbva.apply(generate_shorter_hash, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2e22205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the columns based on the standard order\n",
    "df_bbva = df_bbva[[\n",
    "    'KEY_ID', 'KEY_SYSTEM', 'KEY_ACCOUNT', 'TXT_ACCOUNT', 'KEY_DATE', 'KEY_MONTH', 'KEY_YEAR',\n",
    "    'KEY_ENTITY', 'TXT_ENTITY', 'KEY_TRANSACTION_TYPE', 'TXT_TRANSACTION_TYPE', 'KEY_TRANSACTION_SUBTYPE',\n",
    "    'TXT_TRANSACTION_SUBTYPE', 'TXT_DESC', 'NUM_AMT_NET_REPORTING', 'NUM_AMT_DOCUMENT', 'KEY_CURRENCY_DOCUMENT',\n",
    "    'KEY_RATE', 'FLG_DEBIT_CREDIT', 'KEY_OPERATION', 'TXT_OPERATION', 'DUE_DATE', 'KEY_PAYMENT_TERM',\n",
    "    'TXT_PAYMENT_TERM', 'NUM_AMT_DUE', 'KEY_ID_DUE', 'TXT_ENTITY_DUE', 'TXT_DESC_DUE', 'KEY_COUNTRY',\n",
    "    'TXT_COUNTRY', 'KEY_PURCH_DOC_NO', 'FLG_INTERNAL', 'FLG_CANCEL', 'FLG_REFUND'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3525b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization of the processed data\n",
    "df_bbva.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b582ba",
   "metadata": {},
   "source": [
    "### Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabb24e-776c-42c4-9e3d-4e3548a003b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the cleaned and processed DataFrame to a CSV file\n",
    "\n",
    "try:\n",
    "    # Export DataFrame to the specified output file\n",
    "    df_bbva.to_csv(output_file, index=False)\n",
    "    print(f\"File successfully exported to: {output_file}\")\n",
    "except FileNotFoundError:\n",
    "    # Handle the case where the output directory does not exist\n",
    "    print(f\"Output path not found: {output_file}\")\n",
    "except PermissionError:\n",
    "    # Handle permission issues when writing to the file\n",
    "    print(f\"Permission denied while trying to write to: {output_file}\")\n",
    "except Exception as e:\n",
    "    # Handle any other unforeseen errors during the export\n",
    "    print(f\"An unexpected error occurred while writing the file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalspend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
