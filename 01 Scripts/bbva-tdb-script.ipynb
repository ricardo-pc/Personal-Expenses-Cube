{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53d35dee",
   "metadata": {},
   "source": [
    "### Provision Layer for BBVA bank, debit account\n",
    "\n",
    "**Author**: Ricardo Pérez Castillo\n",
    "\n",
    "**Latest update**: 2024-12-30\n",
    "\n",
    "**Version**: 6.0\n",
    "\n",
    "**Purpose**: Prepare expense data into an unified single source of truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c33042",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Raw File Importing](#raw-file-importing)\n",
    "3. [Data Description](#data-description)\n",
    "4. [Basic Data Cleansing](#basic-data-cleansing)\n",
    "5. [Entity Harmonization](#entity-harmonization)\n",
    "6. [Transaction Type Harmonization](#transaction-type-harmonization)\n",
    "7. [Data Cleansing and Transformation](#data-cleansing-and-transformation)\n",
    "8. [Exporting](#exporting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c4d49",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "BBVA is one of the largest banks in México, offering debit and credit accounts. Data extraction is a challenge, since the bank does not offer API usage. Instead, manual extraction is needed. I use the custom dates option to filter the entire month in one file, however for debit accounts, it is only possible to extract from the latest 2 months, this is quite unfortunate as if you forget to extract the data for one month, then there is no other way to get the data, besides the bank statement which is in PDF format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a548a665",
   "metadata": {},
   "source": [
    "### Raw File Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f58bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical computations\n",
    "from datetime import datetime  # To handle date and time operations\n",
    "import pathlib  # For handling and manipulating file paths in an object-oriented way\n",
    "\n",
    "# Import custom configurations and mappings\n",
    "from config import current_month, current_month_text, current_year  # Custom configurations for date handling\n",
    "from entity_mapping import entity_mapping  # Predefined mapping for harmonizing entities\n",
    "from transaction_subtype_mapping import transaction_subtype_mapping  # Predefined mapping for harmonizing transaction subtypes\n",
    "\n",
    "# Import utilities for fuzzy matching\n",
    "from difflib import get_close_matches  # To find close matches between strings\n",
    "\n",
    "# Import utilities for generating hash values\n",
    "import hashlib  # For generating hash values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbe7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory for file storage\n",
    "base_dir = pathlib.Path.home() / \"Documents\" / \"Finanzas\"\n",
    "# The pathlib.Path.home() dynamically retrieves the user's home directory.\n",
    "\n",
    "# Define the input directory for files\n",
    "input_dir = base_dir / \"BBVA\" / \"BBVA TDB\" / \"Movimientos\" / \"2024\"\n",
    "# This constructs the full path to the directory where input files are stored.\n",
    "# Example: \"C:/Users/YourUserName/Documents/Finanzas/BBVA/BBVA TDB/Movimientos/2024\"\n",
    "\n",
    "# Define the output directory for processed files\n",
    "output_dir = base_dir / \"Personal Spend\" / \"02 Individual Datasets\" / \"2024\"\n",
    "# This constructs the full path to the directory where processed output files will be saved.\n",
    "# Example: \"C:/Users/YourUserName/Documents/Finanzas/Personal Spend/02 Individual Datasets/2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baab912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to construct the input file path for a specific month and year\n",
    "def get_filename_input(month, year, month_text, prefix=\"\", suffix=\"\", extension=\".xlsx\"):\n",
    "    \"\"\"\n",
    "    Constructs a filename for the input file based on the provided parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - month (int): The numeric month (e.g., 1 for January, 12 for December).\n",
    "    - year (int): The year (e.g., 2024).\n",
    "    - month_text (str): The textual representation of the month (e.g., \"January\").\n",
    "    - prefix (str): An optional prefix for the file name (default is an empty string).\n",
    "    - suffix (str): An optional suffix for the file name (default is an empty string).\n",
    "    - extension (str): The file extension (default is \".xlsx\").\n",
    "\n",
    "    Returns:\n",
    "    - str: The constructed file name (e.g., \"01_suffix.xlsx\").\n",
    "    \"\"\"\n",
    "    return str(month).zfill(2) + suffix + extension\n",
    "\n",
    "\n",
    "# Function to construct the output file path for a specific month and year\n",
    "def get_filename_output(month, year, month_text, prefix=\"\", suffix=\"\", extension=\".csv\"):\n",
    "    \"\"\"\n",
    "    Constructs a filename for the output file based on the provided parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - month (int): The numeric month (e.g., 1 for January, 12 for December).\n",
    "    - year (int): The year (e.g., 2024).\n",
    "    - month_text (str): The textual representation of the month (e.g., \"January\").\n",
    "    - prefix (str): An optional prefix for the file name (default is an empty string).\n",
    "    - suffix (str): An optional suffix for the file name (default is an empty string).\n",
    "    - extension (str): The file extension (default is \".csv\").\n",
    "\n",
    "    Returns:\n",
    "    - str: The constructed file name with the format \"month_text/month_textMM.csv\".\n",
    "    \"\"\"\n",
    "    return f\"{month_text}/{prefix}{month_text}{str(month).zfill(2)}{extension}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7349ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file paths for the current month's input and output files\n",
    "\n",
    "# Construct the full input file path\n",
    "input_file = input_dir / get_filename_input(\n",
    "    current_month,\n",
    "    current_year,\n",
    "    current_month_text,\n",
    "    prefix=\"\",\n",
    "    suffix=\"-movimientos\"\n",
    ")\n",
    "\n",
    "# Construct the full output file path\n",
    "output_file = output_dir / get_filename_output(\n",
    "    current_month,\n",
    "    current_year,\n",
    "    current_month_text,\n",
    "    prefix=\"df-bbva-tdb-\",\n",
    "    suffix=\"\"\n",
    ")\n",
    "\n",
    "# Print the constructed file paths\n",
    "print(\"Input file path: \", input_file)\n",
    "print(\"Output file path: \", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e069823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import monthly data from the specified Excel file\n",
    "\n",
    "try:\n",
    "    # Attempt to read the Excel file, skipping the first 3 rows\n",
    "    df_bbva = pd.read_excel(input_file, skiprows=3)\n",
    "    print(\"Data imported successfully!\")\n",
    "except FileNotFoundError:\n",
    "    # Handle the case where the input file is not found\n",
    "    print(f\"File not found: {input_file}\")\n",
    "except Exception as e:\n",
    "    # Handle any other exceptions that may occur during file import\n",
    "    print(f\"An error occurred while reading the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ec635",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "Extract contains\n",
    "- **FECHA**: Date in DD/MM/YYYY format\n",
    "- **DESCRIPCIÓN**: Description that contains the entity and transaction reference number\n",
    "- **CARGO**: Charged amount, mxn\n",
    "- **ABONO**: Deposited amount, mxn\n",
    "- **SALDO**: Balance, mxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23dd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first few rows of the imported data\n",
    "try:\n",
    "    # Display the first five rows of the DataFrame\n",
    "    print(\"Preview of the imported data:\")\n",
    "    display(df_bbva.head())\n",
    "except NameError:\n",
    "    # Handle the case where the DataFrame does not exist\n",
    "    print(\"The data has not been successfully loaded into a DataFrame. Please check the file import process.\")\n",
    "except Exception as e:\n",
    "    # Handle any other unexpected errors\n",
    "    print(f\"An error occurred during data visualization: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df13f4",
   "metadata": {},
   "source": [
    "### Basic Data Cleansing\n",
    "\n",
    "This section focuses on preparing the financial dataset for analysis by removing irrelevant rows, handling missing values, transforming data types, and splitting columns for better structure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4badcb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Remove irrelevant rows\n",
    "df_bbva = df_bbva[df_bbva['FECHA'] != 'BBVA México, S.A. Institución de Banca Múltiple, Grupo Financiero BBVA México.']\n",
    "# Drop rows where 'FECHA' column is missing\n",
    "df_bbva = df_bbva.dropna(subset=['FECHA'])\n",
    "\n",
    "# Step 2: Convert 'FECHA' column to datetime format\n",
    "df_bbva['FECHA'] = pd.to_datetime(df_bbva['FECHA'], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Step 3: Replace null values in numeric columns with zero\n",
    "df_bbva['CARGO'] = df_bbva['CARGO'].fillna(0)\n",
    "df_bbva['ABONO'] = df_bbva['ABONO'].fillna(0)\n",
    "\n",
    "# Step 4: Convert numeric columns from strings to floats\n",
    "# First, ensure all values are strings to handle potential errors\n",
    "df_bbva['CARGO'] = df_bbva['CARGO'].astype(str)\n",
    "df_bbva['ABONO'] = df_bbva['ABONO'].astype(str)\n",
    "df_bbva['SALDO'] = df_bbva['SALDO'].astype(str)\n",
    "\n",
    "# Remove commas and convert to float\n",
    "df_bbva['CARGO'] = df_bbva['CARGO'].str.replace(',', '').astype(float)\n",
    "df_bbva['ABONO'] = df_bbva['ABONO'].str.replace(',', '').astype(float)\n",
    "df_bbva['SALDO'] = df_bbva['SALDO'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Step 5: Split 'DESCRIPCIÓN' column into two separate columns\n",
    "df_bbva[['DESCRIPCION_ENTIDAD', 'DESCRIPCION_DETALLE']] = df_bbva['DESCRIPCIÓN'].str.split('/', n=1, expand=True)\n",
    "\n",
    "# Step 6: Strip whitespace from the new columns\n",
    "df_bbva['DESCRIPCION_ENTIDAD'] = df_bbva['DESCRIPCION_ENTIDAD'].str.strip()\n",
    "df_bbva['DESCRIPCION_DETALLE'] = df_bbva['DESCRIPCION_DETALLE'].str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b30350",
   "metadata": {},
   "source": [
    "### Entity Harmonization\n",
    "\n",
    "This section focuses on standardizing supplier names within the dataset by applying fuzzy matching techniques against a predefined mapping. The goal is to ensure consistency in supplier names for easier analysis and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76c1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_supplier(supplier_name, entity_mapping):\n",
    "    \"\"\"\n",
    "    Harmonizes a supplier name using fuzzy matching against a predefined mapping.\n",
    "\n",
    "    Parameters:\n",
    "    - supplier_name (str): The name of the supplier to be harmonized.\n",
    "    - entity_mapping (dict): A dictionary where keys are potential supplier names \n",
    "                             and values are their harmonized names.\n",
    "\n",
    "    Returns:\n",
    "    - str: The harmonized supplier name if a close match is found; \n",
    "           otherwise, returns the original supplier name.\n",
    "    \"\"\"\n",
    "    # Use fuzzy matching to find potential matches for the supplier name\n",
    "    matches = get_close_matches(supplier_name, entity_mapping.keys(), n=1, cutoff=0.8)\n",
    "    \n",
    "    # Return the harmonized name if a close match is found\n",
    "    if matches:\n",
    "        return entity_mapping[matches[0]]\n",
    "    \n",
    "    # Return the original name if no close match is found\n",
    "    return supplier_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e87734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of suppliers from the 'DESCRIPCION_ENTIDAD' column\n",
    "suppliers_to_harmonize = df_bbva['DESCRIPCION_ENTIDAD'].tolist()\n",
    "\n",
    "# Step 1: Harmonize the supplier names using the mapping\n",
    "harmonized_suppliers = [harmonize_supplier(supplier, entity_mapping) for supplier in suppliers_to_harmonize]\n",
    "\n",
    "# Step 2: Add the harmonized supplier names back to the DataFrame as a new column\n",
    "df_bbva['Harmonized_Supplier'] = harmonized_suppliers\n",
    "\n",
    "\n",
    "# Step 3: Display both 'DESCRIPCION_ENTIDAD' and 'Harmonized_Supplier' for comparison\n",
    "print(\"Comparison of original and harmonized supplier names:\")\n",
    "display(df_bbva[['DESCRIPCIÓN','DESCRIPCION_DETALLE', 'DESCRIPCION_ENTIDAD', 'Harmonized_Supplier']])\n",
    "\n",
    "# Step 4: Review the output and if necessary, update the entity_mapping.py dictionary and re-run the script\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea98022",
   "metadata": {},
   "source": [
    "### Transaction Type Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbc211de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize_transaction_subtype(transaction_desc, transaction_subtype_mapping):\n",
    "    \"\"\"\n",
    "    Harmonizes the transaction subtype description using fuzzy matching against a predefined mapping.\n",
    "\n",
    "    Parameters:\n",
    "    - transaction_desc (str): The name of the transaction descriptions to be harmonized.\n",
    "    - entity_mapping (dict): A dictionary where keys are potential transaction descriptions \n",
    "                             and values are their harmonized names.\n",
    "\n",
    "    Returns:\n",
    "    - str: The harmonized transaction subtype if a close match is found; \n",
    "           otherwise, returns the original transaction description.\n",
    "    \"\"\"\n",
    "    # Use fuzzy matching to find potential matches for the transaction subtype\n",
    "    matches = get_close_matches(transaction_desc, transaction_subtype_mapping.keys(), n=1, cutoff=0.8)\n",
    "    \n",
    "    # Return the harmonized name if a close match is found\n",
    "    if matches:\n",
    "        return transaction_subtype_mapping[matches[0]]\n",
    "    \n",
    "    # Return the original name if no close match is found\n",
    "    return transaction_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of transaction descriptions from the 'DESCRIPCION_DETALLE' column\n",
    "transactions_to_harmonize = df_bbva['DESCRIPCION_DETALLE'].tolist()\n",
    "\n",
    "# Step 1: Harmonize the transaction descriptions using the mapping\n",
    "harmonized_transactions = [harmonize_transaction_subtype(transaction, transaction_subtype_mapping) for transaction in transactions_to_harmonize]\n",
    "\n",
    "# Step 2: Add the harmonized supplier names back to the DataFrame as a new column\n",
    "df_bbva['Harmonized_Transaction_Subtype'] = harmonized_transactions\n",
    "\n",
    "# Step 3: Display both 'DESCRIPCION_DETALLE' and 'harmonized_transactions' for comparison\n",
    "print(\"Comparison of original and harmonized transaction:\")\n",
    "display(df_bbva[['DESCRIPCIÓN','DESCRIPCION_DETALLE', 'Harmonized_Transaction_Subtype']])\n",
    "\n",
    "# Step 4: Review the output and if necessary, update the transaction_subtype_mapping.p dictionary and re-run the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of transaction descriptions from the 'DESCRIPCION_ENTIDAD' column\n",
    "transactions_to_harmonize = df_bbva['DESCRIPCION_ENTIDAD'].tolist()\n",
    "\n",
    "# Step 1: Harmonize the transaction descriptions using the mapping\n",
    "harmonized_transactions = [harmonize_transaction_subtype(transaction, transaction_subtype_mapping) for transaction in transactions_to_harmonize]\n",
    "\n",
    "# Step 2: Add the harmonized supplier names back to the DataFrame as a new column\n",
    "df_bbva['Harmonized_Transaction_Subtype'] = harmonized_transactions\n",
    "\n",
    "# Step 3: Display both 'DESCRIPCION_DETALLE' and 'harmonized_transactions' for comparison\n",
    "print(\"Comparison of original and harmonized transaction:\")\n",
    "display(df_bbva[['DESCRIPCIÓN','DESCRIPCION_ENTIDAD', 'Harmonized_Transaction_Subtype']])\n",
    "\n",
    "# Step 4: Review the output and if necessary, update the transaction_subtype_mapping.py dictionary and re-run the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99e86db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Transaction_Type' based on the given conditions\n",
    "df_bbva['TXT_TRANSACTION_TYPE'] = np.where(df_bbva['CARGO'] != 0, 'Expense', \n",
    "                                       np.where(df_bbva['ABONO'] != 0, 'Deposit', '-1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbva.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf790c",
   "metadata": {},
   "source": [
    "### Data Cleansing and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf73bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that identifies the source system\n",
    "df_bbva['KEY_SYSTEM'] = 'BBVA'\n",
    "\n",
    "# Create a new column that identifies the source account\n",
    "df_bbva['KEY_ACCOUNT'] = 'BBVATDB'\n",
    "df_bbva['TXT_ACCOUNT'] = 'BBVA TDB'\n",
    "\n",
    "# Create a new column that combines CARGO and ABONO columns\n",
    "df_bbva['NUM_AMT_NET_REPORTING'] = np.where(df_bbva['CARGO'] != 0, df_bbva['CARGO'], df_bbva['ABONO']).astype(float)\n",
    "\n",
    "# Create columns that contains the currency-related information\n",
    "df_bbva['NUM_AMT_DOCUMENT'] = df_bbva['NUM_AMT_NET_REPORTING']\n",
    "df_bbva['KEY_CURRENCY_DOCUMENT'] = 'MXN'\n",
    "df_bbva['KEY_RATE'] = 1.0\n",
    "\n",
    "# Create new columns with time information\n",
    "df_bbva['KEY_MONTH'] = df_bbva['FECHA'].dt.month\n",
    "df_bbva['KEY_YEAR'] = df_bbva['FECHA'].dt.year\n",
    "\n",
    "# Create a new column that contains the flag indicating whether the transaction is debit or credit\n",
    "df_bbva['FLG_DEBIT_CREDIT'] = np.where(df_bbva['CARGO'] != 0, 'C', 'D')\n",
    "\n",
    "# Create new columns that identify the grouping operation (project, vacation, etc.). These will be blank and filled in later.\n",
    "df_bbva['KEY_OPERATION'] = ''\n",
    "df_bbva['TXT_OPERATION'] = ''\n",
    "\n",
    "# Create new columns relevant for credit card transactions and payments in installments. Not relevant for this account.\n",
    "df_bbva['DUE_DATE'] = ''\n",
    "df_bbva['KEY_PAYMENT_TERM'] = ''\n",
    "df_bbva['TXT_PAYMENT_TERM'] = ''\n",
    "df_bbva['NUM_AMT_DUE'] = ''\n",
    "df_bbva['KEY_ID_DUE'] = ''\n",
    "df_bbva['TXT_ENTITY_DUE'] = ''\n",
    "df_bbva['TXT_DESC_DUE'] = ''\n",
    "\n",
    "# Create new columns with the country information. This account does not provide the country information.\n",
    "df_bbva['KEY_COUNTRY'] = 'MX'\n",
    "df_bbva['TXT_COUNTRY'] = 'Mexico'\n",
    "\n",
    "# Create a new column with the purchase document number, blank initially.\n",
    "df_bbva['KEY_PURCH_DOC_NO'] = ''\n",
    "\n",
    "# Create a new column with internal flag\n",
    "df_bbva['FLG_INTERNAL'] = np.where(df_bbva['Harmonized_Supplier'] == 'BBVA Your Name', 'Y', 'N')\n",
    "\n",
    "# Create a new column with flag indicating whether the transaction was canceled\n",
    "df_bbva['FLG_CANCEL'] = ''\n",
    "\n",
    "# Create a new column with flag indicating whether the transaction was refunded\n",
    "df_bbva['FLG_REFUND'] = ''\n",
    "\n",
    "# Create new columns that will be filled later with the master tables\n",
    "df_bbva['KEY_ENTITY'] = ''\n",
    "df_bbva['KEY_TRANSACTION_TYPE'] = ''\n",
    "df_bbva['KEY_TRANSACTION_SUBTYPE'] = ''\n",
    "\n",
    "# Rename the columns to match the standard naming convention\n",
    "df_bbva.rename(columns={\n",
    "    'FECHA': 'KEY_DATE',\n",
    "    'DESCRIPCIÓN': 'TXT_DESC',\n",
    "    'Harmonized_Supplier': 'TXT_ENTITY',\n",
    "    'Harmonized_Transaction_Subtype': 'TXT_TRANSACTION_SUBTYPE'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acbbbd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a hash\n",
    "def generate_shorter_hash(row):\n",
    "    concat_str = f\"{row['KEY_DATE']}_{row['TXT_ENTITY']}_{row['TXT_TRANSACTION_SUBTYPE']}_{row['NUM_AMT_NET_REPORTING']}\"\n",
    "    return hashlib.md5(concat_str.encode('utf-8')).hexdigest()  # MD5 generates a 32-character hash\n",
    "\n",
    "# Apply the function to create the hash-based KEY_ID\n",
    "df_bbva['KEY_ID'] = df_bbva.apply(generate_shorter_hash, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ef9aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the columns based on the standard order\n",
    "df_bbva = df_bbva[[\n",
    "    'KEY_ID', 'KEY_SYSTEM', 'KEY_ACCOUNT', 'TXT_ACCOUNT', 'KEY_DATE', 'KEY_MONTH', 'KEY_YEAR',\n",
    "    'KEY_ENTITY', 'TXT_ENTITY', 'KEY_TRANSACTION_TYPE', 'TXT_TRANSACTION_TYPE', 'KEY_TRANSACTION_SUBTYPE',\n",
    "    'TXT_TRANSACTION_SUBTYPE', 'TXT_DESC', 'NUM_AMT_NET_REPORTING', 'NUM_AMT_DOCUMENT', 'KEY_CURRENCY_DOCUMENT',\n",
    "    'KEY_RATE', 'FLG_DEBIT_CREDIT', 'KEY_OPERATION', 'TXT_OPERATION', 'DUE_DATE', 'KEY_PAYMENT_TERM',\n",
    "    'TXT_PAYMENT_TERM', 'NUM_AMT_DUE', 'KEY_ID_DUE', 'TXT_ENTITY_DUE', 'TXT_DESC_DUE', 'KEY_COUNTRY',\n",
    "    'TXT_COUNTRY', 'KEY_PURCH_DOC_NO', 'FLG_INTERNAL', 'FLG_CANCEL', 'FLG_REFUND'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5c9cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final visualization of the processed data\n",
    "df_bbva.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef20831",
   "metadata": {},
   "source": [
    "### Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae4702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the cleaned and processed DataFrame to a CSV file\n",
    "\n",
    "try:\n",
    "    # Export DataFrame to the specified output file\n",
    "    df_bbva.to_csv(output_file, index=False)\n",
    "    print(f\"File successfully exported to: {output_file}\")\n",
    "except FileNotFoundError:\n",
    "    # Handle the case where the output directory does not exist\n",
    "    print(f\"Output path not found: {output_file}\")\n",
    "except PermissionError:\n",
    "    # Handle permission issues when writing to the file\n",
    "    print(f\"Permission denied while trying to write to: {output_file}\")\n",
    "except Exception as e:\n",
    "    # Handle any other unforeseen errors during the export\n",
    "    print(f\"An unexpected error occurred while writing the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dbea5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalspend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
